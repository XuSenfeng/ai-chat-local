{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiao\\AppData\\Local\\Temp\\ipykernel_33924\\4280861123.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('model_furina/model_2025_02_04_15_41_53.pth')\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'no', 'score': 0.9056112170219421},\n",
       " {'label': 'no', 'score': 0.9552835822105408},\n",
       " {'label': 'no', 'score': 0.8829072713851929},\n",
       " {'label': 'yes', 'score': 0.834133505821228},\n",
       " {'label': 'no', 'score': 0.9279910922050476},\n",
       " {'label': 'yes', 'score': 0.9634923934936523},\n",
       " {'label': 'yes', 'score': 0.967900276184082},\n",
       " {'label': 'yes', 'score': 0.9298421144485474}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 文本分类模型微调的示例\n",
    "from transformers import AutoTokenizer\n",
    "# 加载模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./hflrbt3\")\n",
    "model = torch.load('model_furina/model_2025_02_04_15_41_53.pth')\n",
    "model.eval()\n",
    "id2label = {0:\"no\", 1:\"yes\"}\n",
    "sen = [\"服从命令, 芙宁娜女士\",\n",
    "       \"你今天怎么样\",\n",
    "       \"我要去上班了\",\n",
    "       \"给我今天的新闻\",\n",
    "       \"你是谁\",\n",
    "       \"看一下最近的股票行情\",\n",
    "       \"给我讲解一下这一个项目的情况\",\n",
    "       \"项目的情况怎么样了\"]\n",
    "from transformers import pipeline\n",
    "model.config.id2label = id2label\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "pipe(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'no', 'score': 0.9489531517028809},\n",
       " {'label': 'no', 'score': 0.6886082887649536},\n",
       " {'label': 'no', 'score': 0.9056112170219421},\n",
       " {'label': 'no', 'score': 0.9143954515457153},\n",
       " {'label': 'no', 'score': 0.9552835822105408},\n",
       " {'label': 'no', 'score': 0.9614712595939636},\n",
       " {'label': 'no', 'score': 0.9431222081184387},\n",
       " {'label': 'no', 'score': 0.9308228492736816},\n",
       " {'label': 'no', 'score': 0.9267386794090271},\n",
       " {'label': 'no', 'score': 0.9052245020866394},\n",
       " {'label': 'yes', 'score': 0.9645366668701172},\n",
       " {'label': 'yes', 'score': 0.9613882899284363},\n",
       " {'label': 'yes', 'score': 0.9616449475288391},\n",
       " {'label': 'yes', 'score': 0.9616520404815674},\n",
       " {'label': 'yes', 'score': 0.9592236876487732},\n",
       " {'label': 'yes', 'score': 0.7594723701477051}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = [\"你喜欢什么东西?\",\n",
    "       \"明天的外卖吃什么好,你有啥推荐的?\",\n",
    "       \"服从命令, 芙宁娜女士\",\n",
    "       \"你好, 今天天气怎么样\",\n",
    "       \"你今天怎么样\",\n",
    "       \"(开心地笑), 亲爱的，我今天买了一束你最喜欢的花！\",\n",
    "       \"(撒娇语气), 宝宝，陪我一起看这部新出的电视剧好不好嘛？\",\n",
    "       \"宝贝，你猜我今天在路上碰到谁了？(好奇地问), \",\n",
    "       \"亲爱的，(认真地说), 我想和你一起去学一门新的语言。\",\n",
    "       \"(兴奋地跳), 宝，我们周末去游乐园玩吧！\",\n",
    "       \"亲爱的，麻烦你帮我查询一下明天北京到深圳的航班动态，看看有没有晚点。\",\n",
    "       \"宝宝，能不能拜托你帮我获取一下今天某知名股票的实时股价走势，我关注好久了。\",\n",
    "       \"宝贝，帮我查查距离咱们家最近的三甲医院的挂号方式，我有点不舒服想去看看。\",\n",
    "       \"亲爱的，务必帮我搜索一下最近一个月内周杰伦在各大音乐平台的歌曲播放量，我好奇好久了。\",\n",
    "       \"宝，辛苦你帮我了解下本市下周有哪些正在举办的艺术展览，我想去逛逛。\",\n",
    "       \"给我开一下空调呗, 我有点冷了\"]\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "pipe(sen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
