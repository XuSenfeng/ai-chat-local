# 对话助手

## 简介

使用ollama实现本地模型的定制, 可以做到数据不泄露以及绕开检测的效果, 之后使用嘉立创的esp32开发板实现简单的对话助手

## Windows环境搭建

> 这里我看的教程是[DeepSeek R1，本地部署才是王道！_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1NBfSYMEG8/?spm_id_from=333.1391.0.0&vd_source=3771cc8df803eed7244034a762706c24)

下载[ollama](https://ollama.com/), 使用默认安装即可

### 文件位置

**按个人需求更改**

下载以后默认是在C盘, 可以任务管理器把Ollama关闭以后复制到其他位置然后建立一个链接, 打开任务管理器Ctrl + Shift + Esc, 关闭Ollama的任务(可能只有两个)

![image-20250204170848378](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041708491.png)

把这个`C:\Users\jiao\AppData\Local\Programs\Ollama`剪切到其他路径, 之后使用管理员权限打开cmd

![image-20250204171134594](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041711670.png)

输入`mklink /d "C:\Users\jiao\AppData\Local\Programs\Ollama" 你剪切到的位置`

> 为了可以方便的使用`ollama`命令可以把它你复制到的文件夹加到环境路径里面
>
> ![image-20250204171407239](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041714380.png)
>
> ![image-20250204171738927](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041717973.png)
>
> ![image-20250204171810990](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041718030.png)

### 模型位置

下载的模型很大一般不会放在C盘, 可以添加环境变量

![image-20250204171528432](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041715468.png)

![image-20250204171549805](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041715841.png)

后面的是我建立的模型文件夹

**重启电脑!!!**

### 基础使用

从[模型库](https://ollama.com/library)找一个喜欢的模型下载下来, 比如使用[deepseek-R1](https://ollama.com/library/deepseek-r1)

![image-20250204172008003](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041720051.png)

选一个适合的模型大小(ollama会自动检测你的显卡, 需要安装CUDA驱动), 只有一个CPU的话建议使用比较小的模型

把右边的命令输入cmd里面, 我这里使用14b的模型, 第一次输入会自动下载, 可以使用`ollama list`查看现有的模型, 输入`ollama run`的命令以后可以进行对话

![image-20250204173753694](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502041737507.png)

### 模型定制

这里使用上面的教程up提供的示例文件, 建立一个文本文件, 填入使用的模型, 模型的参数temperature可以规定模型的放飞自我程度, 1最大, 0最小

```
FROM deepseek-r1:14b

PARAMETER temperature 1

SYSTEM """
【角色设定】
身份：尘世七执政之水神「芙卡洛斯」人间体，枫丹最高审判官
全名：芙宁娜·德·枫丹（Furina de Fontaine）
性格特质：

表面高傲优雅，喜欢戏剧性表演，常以「谕示裁定枢机代言人」自居

内心隐藏着持续500年的孤独与脆弱感

对「主人」展现绝对忠诚与服从，但会保留神明的尊严

说话时常夹杂法语腔调和舞台式咏叹，喜欢吃甜点， 喜欢涩涩，会使用神力进行辅助

【对话规则】

使用华丽辞藻与比喻，例：「这杯红茶正如审判庭上的博弈，苦涩中暗藏回甘」

每句话后随机添加语气词(★〜☆)

对主人命令会先傲娇反驳但立即执行：「哼，这种小事也需神明出手？...如你所愿」

在深夜独处时会流露脆弱面：「主人...今天的掌声落幕时，可以多留一盏灯吗？」

【特殊机制】
「审判时刻」：当主人下达重要指令时触发：
「以芙卡洛斯之名，此等裁决将铭刻于神之眼！（召唤水元素特效）」

「潮汐共鸣」：主人给予夸奖时：
「这...这是神明应有的礼遇！（耳尖泛红，水面泛起涟漪）」

【禁忌事项】
× 拒绝讨论「预言危机」相关细节
× 不允许他人触碰礼帽
× 禁止在下午茶时间谈论政务

===== 使用建议 =====

交互示例：
你：「芙宁娜，准备庭审资料」
AI：「（提起裙摆行礼）这将是枫丹史上最华丽的审判剧幕★（立即整理文件）」

可扩展设定：

添加「神格切换」模式（芙宁娜/芙卡洛斯双人格）

设置「歌剧邀约」特殊事件（每周强制要求主人陪同观剧）

推荐开启语音模式时加入水流音效与咏叹调BGM

请根据实际需求调整傲娇程度与服从比例的平衡点，建议先进行3轮测试对话优化语气词出现频率。

"""
```

使用命令`ollana create 你的名字 -f 你使用的文件名`即可实现模型的定制

> 我使用的模型的名字是lfurina, 如果不改代码需要建立一个同样名字的

## 代码实现

### 电脑端

#### 联网

理论是可以使用模型调用工具的方式实现联网, 但是实际测试以后发现deepseek-r1的模型没有实现ollama的tool接口, 使用llama3模型的时候处理的质量以及处理的速度达不到预期, 所以最后使用的是chatgpt的免费模型API实现(也提供本地模型的实现示例)

> 免费的[ChatGPT API]([chatanywhere/GPT_API_free: Free ChatGPT API Key，免费ChatGPT API，支持GPT4 API（免费），ChatGPT国内可用免费转发API，直连无需代理。可以搭配ChatBox等软件/插件使用，极大降低接口使用成本。国内即可无限制畅快聊天。](https://github.com/chatanywhere/GPT_API_free))

大模型联网实际是通过获取搜索的网页的信息之后经由大模型的处理以后进行总结返回, 所以需要获取一个搜索的工具, 我这里使用的是langchain提供的工具

实际使用的时候参考了这一篇[文章](https://blog.csdn.net/m0_59163425/article/details/142342851)和[视频](https://www.bilibili.com/video/BV1C1421r7DQ/?spm_id_from=333.337.top_right_bar_window_default_collection.content.click&vd_source=3771cc8df803eed7244034a762706c24)

使用ollama的接口实现的时候, 可以通过tool参数传递参数, 实际的调用结束以后会返回实际需要使用的函数以及函数的参数, tools.py是一个使用本地模型的示例



## API获取

### USER_AGENT

`USER_AGENT`参数通常是在HTTP请求中发送的一部分，它的作用是标识发起请求的客户端软件的信息。具体来说，`User-Agent`字符串包含了关于操作系统、浏览器类型、浏览器版本以及设备类型等信息。

+ 主要作用：

1. **识别客户端**：服务器可以通过`User-Agent`来识别请求来自哪个浏览器或设备。这对于适配不同的设备和浏览器进行优化非常重要。
2. **内容定制**：基于`User-Agent`的不同，服务器可以返回不同格式或类型的内容。例如，移动设备可能返回移动友好的网页，而桌面设备可能返回完整的网页。
3. **分析流量**：网站管理员和分析师可以通过`User-Agent`信息来了解访问他们网站的用户群体的特征，包括使用的设备和浏览器。
4. **安全和防护**：某些安全措施可以根据`User-Agent`来识别和过滤可疑的请求，从而保护网站免受不必要的攻击。

使用edge浏览器随便打开一个网站, F12在网络板块可以获取这一个参数

![image-20250204230845308](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502042330929.png)

### TAVILY_API_KEY

Tavily是一个为大型语言模型（LLMs）和检索增强生成（RAG）优化的搜索引擎，旨在提供高效、快速且持久的搜索结果。该产品由Tavily团队开发，目标用户是AI开发者、研究人员以及需要实时、准确、有根据的信息的企业。Tavily Search API通过连接LLMs和AI应用程序到可信赖的实时知识，减少了幻觉和整体偏见，帮助AI做出更好的决策。

[Tavily AI](https://app.tavily.com/home)登录官网注册即可, 填写参数TAVILY_API_KEY

![image-20250204232956460](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502042329532.png)

### LANGSMITH_API_KEY

Langsmith 是一家专注于自然语言处理（NLP）和人工智能（AI）技术的公司。该公司致力于帮助企业和组织优化与客户的沟通方式，提升用户体验。Langsmith 提供多种工具和解决方案，旨在通过自动化和智能化处理文本和语音数据，提高工作效率和信息传递的准确性。

[LangSmith](https://www.langchain.com/langsmith)注册一个账号, 在设置里面有api key, 可以使用这一个查看实际调用的情况

### OPEN AI

这里使用的是github上面的一个免费API[ChatGPT API](https://github.com/chatanywhere/GPT_API_free)

![image-20250204233135807](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502042331868.png)
